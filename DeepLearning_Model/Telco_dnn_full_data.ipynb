{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/encore/workspaces/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(df:pd.DataFrame):\n",
    "    print(f'Head(3):\\n{\"=\"*80}')\n",
    "    print(df.head(3))\n",
    "    print('=' * 80)\n",
    "    print(f'\\nShape:\\n{\"=\"*80}')\n",
    "    print(df.shape)\n",
    "    print('=' * 80)\n",
    "    print(f'\\nInfo:\\n{\"=\"*80}')\n",
    "    print(df.info())\n",
    "    print('=' * 80)\n",
    "    print(f'\\nDescribe Number columns:\\n{\"=\"*80}')\n",
    "    print(df.describe())\n",
    "    print('=' * 80)\n",
    "    print(f'\\nDescribe Object columns:\\n{\"=\"*80}')\n",
    "    print(df.describe(include='object'))\n",
    "    print('=' * 80)\n",
    "    print(f'\\n결측치:\\n{\"=\"*80}')\n",
    "    print(df.isnull().sum())\n",
    "    print('=' * 80)\n",
    "    print(f'\\n이상치:\\n{\"=\"*80}')\n",
    "    df.select_dtypes(exclude='object').boxplot(figsize=(20,10))\n",
    "    plt.show()\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cell2celltrain.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'NewCellphoneUser' : {'No' : 0, 'Yes' :1},\n",
    "    'NotNewCellphoneUser' : {'No' : 0, 'Yes' : 1},\n",
    "    'MadeCallToRetentionTeam' : {'No' : 0, 'Yes' : 1},\n",
    "    'CreditRating' : {'1-Highest' : 1, '4-Medium': 4,  '3-Good': 3, '2-High' : 2, '5-Low' : 5, '6-VeryLow' : 6, '7-Lowest' : 7},\n",
    "    'Churn' : {'No':0, 'Yes': 1},\n",
    "    'ChildrenInHH': {'No':0, 'Yes': 1},\n",
    "    'HandsetRefurbished': {'No':0, 'Yes': 1},\n",
    "    'MaritalStatus': {'No':0, 'Yes': 1},\n",
    "    'HandsetWebCapable': {'No':0, 'Yes': 1},\n",
    "    'TruckOwner': {'No':0, 'Yes': 1},\n",
    "    'RVOwner': {'No':0, 'Yes': 1},\n",
    "    'Homeownership': {'Unknown':0, 'Known': 1},\n",
    "    'BuysViaMailOrder': {'No':0, 'Yes': 1},\n",
    "    'RespondsToMailOffers': {'No':0, 'Yes': 1},\n",
    "    'OwnsComputer': {'No':0, 'Yes': 1},\n",
    "    'HasCreditCard': {'No':0, 'Yes': 1},\n",
    "    'OwnsMotorcycle': {'No':0, 'Yes': 1},\n",
    "    'NonUSTravel': {'No':0, 'Yes': 1},\n",
    "    'OptOutMailings': {'No':0, 'Yes': 1}\n",
    "}\n",
    "for col, mapping in mappings.items():\n",
    "    try:\n",
    "        df[col] = df[col].map(mapping)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.HandsetPrice = df.HandsetPrice.apply(lambda x : int(x) if x != 'Unknown' else 0)\n",
    "price_mean = df.HandsetPrice.mean()\n",
    "df.HandsetPrice = df.HandsetPrice.apply(lambda x : x if x > 0 else price_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PrizmCode': LabelEncoder(),\n",
       " 'Occupation': LabelEncoder(),\n",
       " 'ServiceArea': LabelEncoder()}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoders = {}\n",
    "for col in ['PrizmCode','Occupation','ServiceArea']:\n",
    "    le = LabelEncoder()\n",
    "    encoders[col] = le\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['CustomerID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    22484\n",
       "1     8639\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df[df.Churn == 0][:8639], df[df.Churn == 1]] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[['MonthlyRevenue', 'ServiceArea',\n",
    "             'RoamingCalls','PercChangeRevenues','MonthsInService','RetentionCalls',\n",
    "             'RetentionOffersAccepted','ReferralsMadeBySubscriber','AdjustmentsToCreditRating',\n",
    "             'MadeCallToRetentionTeam','PeakCallsInOut',\n",
    "             'ReceivedCalls','UnansweredCalls','OutboundCalls',\n",
    "             'DroppedCalls','InboundCalls','BlockedCalls',\n",
    "             'DirectorAssistedCalls','CustomerCareCalls', 'CurrentEquipmentDays'\n",
    "             ]].copy()\n",
    "\n",
    "y_data = df['Churn'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_ = df[['CustomerID','MonthlyRevenue','MonthlyMinutes','TotalRecurringCharge','OverageMinutes',\n",
    "             'RoamingCalls','PercChangeMinutes','PercChangeRevenues','MonthsInService','RetentionCalls',\n",
    "             'RetentionOffersAccepted','NewCellphoneUser','NotNewCellphoneUser','ReferralsMadeBySubscriber',\n",
    "             'AdjustmentsToCreditRating','MadeCallToRetentionTeam','CreditRating','PeakCallsInOut',\n",
    "             'OffPeakCallsInOut','ReceivedCalls','UnansweredCalls','OutboundCalls','DroppedBlockedCalls',\n",
    "             'DroppedCalls','InboundCalls','BlockedCalls','DirectorAssistedCalls','CustomerCareCalls',\n",
    "             'CallWaitingCalls','CurrentEquipmentDays','HandsetRefurbished','IncomeGroup','PrizmCode',\n",
    "             'Occupation','MaritalStatus','HandsetModels','AgeHH1','ChildrenInHH', 'Churn']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, \n",
    "                                                    test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13822, 20), (3456, 20), (13822,), (3456,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor( X_train, dtype=torch.float32).to('cuda:0'), \n",
    "                                               torch.tensor( y_train.to_numpy(), dtype=torch.float32).to('cuda:0'))\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor( X_test,  dtype=torch.float32).to('cuda:0'), \n",
    "                                               torch.tensor( y_test.to_numpy(), dtype=torch.float32).to('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ChurnModel,self).__init__()\n",
    "        self.fc1   = nn.Linear(input_size, 1024)\n",
    "        self.fc2   = nn.Linear(1024, 1024)\n",
    "        self.fc3   = nn.Linear(1024, 512)\n",
    "        self.fc4   = nn.Linear(512, 512)\n",
    "        self.fc5   = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnModel2(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ChurnModel2,self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.fc1_1   = nn.Linear(input_size//3, 512)\n",
    "        self.fc1_2   = nn.Linear(input_size//3, 512)\n",
    "        self.fc1_3   = nn.Linear(input_size//3 + input_size%3, 512)\n",
    "\n",
    "        self.fc2_1   = nn.Linear(512, 512)\n",
    "        self.fc2_2   = nn.Linear(512, 512)\n",
    "        self.fc2_3   = nn.Linear(512, 512)\n",
    "\n",
    "        self.fc3   = nn.Linear(512 * 3, 256)\n",
    "        # self.fc4   = nn.Linear(256, 64)\n",
    "     \n",
    "        self.fc5   = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        d_ = self.input_size//3\n",
    "        x1 = x[:, :d_]\n",
    "        x2 = x[:, d_:d_ *2]\n",
    "        x3 = x[:, d_*2:]\n",
    "\n",
    "        x1 = self.fc1_1(x1)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        x2 = self.fc1_2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        x3 = self.fc1_3(x3)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "\n",
    "        x1 = self.fc2_1(x1)\n",
    "        x1 = F.leaky_relu(x1)\n",
    "        x2 = self.fc2_2(x2)\n",
    "        x2 = F.leaky_relu(x2)\n",
    "        x3 = self.fc2_3(x3)\n",
    "        x3 = F.leaky_relu(x3)\n",
    "\n",
    "        x4 = torch.cat((x1, x2, x3), dim=1)\n",
    "        # print(x1.shape, x2.shape, x3.shape, x4.shape)\n",
    "        \n",
    "        x4 = self.fc3(x4)\n",
    "        x4 = F.leaky_relu(x4)\n",
    "\n",
    "        # x4 = self.fc4(x4)\n",
    "        # x4 = F.leaky_relu(x4)\n",
    "  \n",
    "        x4 = self.fc5(x4)\n",
    "        x4 = torch.sigmoid(x4)\n",
    "\n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        # display(preds, y)\n",
    "        loss = loss_fn(preds, y.reshape(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_acc += ((preds>=0.5).float() ==  y.reshape(-1,1)).float().sum().item()\n",
    "        total_loss += loss.item()*y.size(0)\n",
    "        # print(f'total_loss = {total_loss}, total_acc={total_acc}')\n",
    "    return total_acc/len(train_loader.dataset), total_loss/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "\n",
    "    with torch.no_grad():   # torch를 변경하지 마라. 테스트 동안\n",
    "        for X, y in test_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, y.reshape(-1,1))\n",
    "\n",
    "            total_acc += ((preds>=0.5).float() ==  y.reshape(-1,1)).float().sum().item()\n",
    "            total_loss += loss.item()*y.size(0)\n",
    "\n",
    "    return total_acc/len(test_loader.dataset), total_loss/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8b2e4b0c70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(num_epochs,model, train_loader, test_loader, optimizer, loss_fn):\n",
    "    for epoch in range(num_epochs):\n",
    "        acc_train, loss_train = train(model, train_loader, optimizer, loss_fn)\n",
    "        acc_valid, loss_valid = evaluate(model, test_loader, loss_fn)\n",
    "        print(f'에포크 {epoch} 정확도: {acc_train:.4f} 검증 정확도: {acc_valid:.4f} \\\n",
    "            훈련 Loss: {loss_train:.4f} 검증 Loss: {loss_valid:.4f}')\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** ChurnModel ********************\n",
      "--------------- BCELoss ---------------\n",
      "에포크 0 정확도: 0.7385 검증 정확도: 0.7459             훈련 Loss: 0.5174 검증 Loss: 0.4879\n",
      "에포크 1 정확도: 0.7536 검증 정확도: 0.7405             훈련 Loss: 0.4816 검증 Loss: 0.4855\n",
      "에포크 2 정확도: 0.7558 검증 정확도: 0.7439             훈련 Loss: 0.4773 검증 Loss: 0.4818\n",
      "에포크 3 정확도: 0.7565 검증 정확도: 0.7494             훈련 Loss: 0.4817 검증 Loss: 0.4804\n",
      "에포크 4 정확도: 0.7584 검증 정확도: 0.7477             훈련 Loss: 0.4711 검증 Loss: 0.4881\n",
      "에포크 5 정확도: 0.7580 검증 정확도: 0.7462             훈련 Loss: 0.4751 검증 Loss: 0.4813\n",
      "에포크 6 정확도: 0.7636 검증 정확도: 0.7509             훈련 Loss: 0.4706 검증 Loss: 0.5040\n",
      "에포크 7 정확도: 0.7608 검증 정확도: 0.7457             훈련 Loss: 0.4645 검증 Loss: 0.4777\n",
      "에포크 8 정확도: 0.7602 검증 정확도: 0.7468             훈련 Loss: 0.4714 검증 Loss: 0.4840\n",
      "에포크 9 정확도: 0.7645 검증 정확도: 0.7237             훈련 Loss: 0.4650 검증 Loss: 0.4962\n",
      "--------------- HingeEmbeddingLoss ---------------\n",
      "에포크 0 정확도: 0.5120 검증 정확도: 0.4965             훈련 Loss: 0.5128 검증 Loss: 0.4965\n",
      "에포크 1 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 2 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 3 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 4 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 5 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 6 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 7 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 8 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 9 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "--------------- BCEWithLogitsLoss ---------------\n",
      "에포크 0 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "에포크 1 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "에포크 2 정확도: 0.5008 검증 정확도: 0.4965             훈련 Loss: 0.6932 검증 Loss: 0.6931\n",
      "에포크 3 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "에포크 4 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "에포크 5 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "에포크 6 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "에포크 7 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "에포크 8 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "에포크 9 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.6931 검증 Loss: 0.6931\n",
      "******************** ChurnModel2 ********************\n",
      "--------------- BCELoss ---------------\n",
      "에포크 0 정확도: 0.7455 검증 정확도: 0.7445             훈련 Loss: 0.4901 검증 Loss: 0.4801\n",
      "에포크 1 정확도: 0.7521 검증 정확도: 0.7483             훈련 Loss: 0.4809 검증 Loss: 0.4763\n",
      "에포크 2 정확도: 0.7543 검증 정확도: 0.7494             훈련 Loss: 0.4801 검증 Loss: 0.4894\n",
      "에포크 3 정확도: 0.7562 검증 정확도: 0.7431             훈련 Loss: 0.4701 검증 Loss: 0.4780\n",
      "에포크 4 정확도: 0.7566 검증 정확도: 0.7468             훈련 Loss: 0.4732 검증 Loss: 0.4838\n",
      "에포크 5 정확도: 0.7564 검증 정확도: 0.7471             훈련 Loss: 0.4646 검증 Loss: 0.4771\n",
      "에포크 6 정확도: 0.7579 검증 정확도: 0.7454             훈련 Loss: 0.4695 검증 Loss: 0.4780\n",
      "에포크 7 정확도: 0.7592 검증 정확도: 0.7462             훈련 Loss: 0.4683 검증 Loss: 0.4755\n",
      "에포크 8 정확도: 0.7575 검증 정확도: 0.7494             훈련 Loss: 0.4750 검증 Loss: 0.4749\n",
      "에포크 9 정확도: 0.7573 검증 정확도: 0.7532             훈련 Loss: 0.4666 검증 Loss: 0.4790\n",
      "--------------- HingeEmbeddingLoss ---------------\n",
      "에포크 0 정확도: 0.5095 검증 정확도: 0.4965             훈련 Loss: 0.5109 검증 Loss: 0.4965\n",
      "에포크 1 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 2 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 3 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 4 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 5 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 6 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 7 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 8 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "에포크 9 정확도: 0.5009 검증 정확도: 0.4965             훈련 Loss: 0.5009 검증 Loss: 0.4965\n",
      "--------------- BCEWithLogitsLoss ---------------\n",
      "에포크 0 정확도: 0.7125 검증 정확도: 0.7439             훈련 Loss: 0.6147 검증 Loss: 0.6005\n",
      "에포크 1 정확도: 0.7534 검증 정확도: 0.7399             훈련 Loss: 0.5995 검증 Loss: 0.6036\n",
      "에포크 2 정확도: 0.7487 검증 정확도: 0.7445             훈련 Loss: 0.6032 검증 Loss: 0.6017\n",
      "에포크 3 정확도: 0.7534 검증 정확도: 0.7486             훈련 Loss: 0.5990 검증 Loss: 0.5996\n",
      "에포크 4 정확도: 0.7503 검증 정확도: 0.7410             훈련 Loss: 0.6046 검증 Loss: 0.6011\n",
      "에포크 5 정확도: 0.7512 검증 정확도: 0.7442             훈련 Loss: 0.6019 검증 Loss: 0.6076\n",
      "에포크 6 정확도: 0.7474 검증 정확도: 0.7491             훈련 Loss: 0.6041 검증 Loss: 0.6043\n",
      "에포크 7 정확도: 0.7460 검증 정확도: 0.7474             훈련 Loss: 0.6037 검증 Loss: 0.6012\n",
      "에포크 8 정확도: 0.7496 검증 정확도: 0.7422             훈련 Loss: 0.6059 검증 Loss: 0.6062\n",
      "에포크 9 정확도: 0.7502 검증 정확도: 0.7454             훈련 Loss: 0.6041 검증 Loss: 0.6030\n"
     ]
    }
   ],
   "source": [
    "loss_fns = {'BCELoss': nn.BCELoss(), \n",
    "            'HingeEmbeddingLoss': nn.HingeEmbeddingLoss(), \n",
    "            'BCEWithLogitsLoss': nn.BCEWithLogitsLoss() }\n",
    "\n",
    "models = {'ChurnModel' : ChurnModel(train_dataset[0][0].__len__()), \n",
    "          'ChurnModel2': ChurnModel2(train_dataset[0][0].__len__())}\n",
    "for model_name, model in models.items():\n",
    "    model.to('cuda:0')\n",
    "    print(f'{\"*\"*20} {model_name} {\"*\"*20}')\n",
    "    for fn_name, loss_fn in loss_fns.items():\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        print(f'{\"-\"*15} {fn_name} {\"-\"*15}')\n",
    "        learning(num_epochs, model, train_loader, test_loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
