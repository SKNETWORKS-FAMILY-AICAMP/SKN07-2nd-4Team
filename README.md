

### 5. 프로젝트 결과

<br>

#### 1) 모델 성능 평가
각 모델의 성능은 교차 검증을 통해 검토되었으며, 주요 평가지표인 **정확도(Accuracy)** 와 **ROC-AUC** 를 기준으로 평가하였습니다.

#### 2) 모델링
로지스틱 회귀(Logistic Regression), 결정 트리(Decision Tree), 랜덤 포레스트(Random Forest), 그래디언트 부스팅(Gradient Boosting), XGBoost 등 다양한 모델이 실험되었습니다.

![image](https://github.com/user-attachments/assets/a81a10ad-a4ab-459a-b274-791ee17cc094) ![image](https://github.com/user-attachments/assets/feda1fe3-2ead-49a9-942c-f18bd6129092)
    

각 모델의 성능 확인 결과 **랜덤 포레스트**와 **XGBoost** 모델은 **ROC-AUC** 점수가 높게 나와, 모델의 **분류 성능**이 우수함을 확인했습니다.

<br>

> 성능 분석 및 시사점
 - XGBoost 모델과 랜덤 포레스트(Random Forest) 모델은 교차 검증에서 뛰어난 성능을 보였으나, 실제 테스트 데이터에서는 다소 성능이 떨어졌습니다. <br>
   이는 학습 데이터와 테스트 데이터 간의 차이, 또는 모델이 일부 과적합된 결과일 수 있습니다.
 - **정확도**와 **ROC-AUC** 모두 꽤 우수한 결과를 나타내었고, 특히 ROC-AUC 지표는 이탈 예측 문제에서 모델의 성능을 더욱 잘 평가할 수 있는 지표로, XGBoost가 긍정적 클래스를 잘 구분하는 능력을 보여주었습니다.
 - **모델의 향후 개선 방향**으로는, 과적합을 방지하기 위한 추가적인 하이퍼파라미터 튜닝, 테스트 데이터에 대한 성능 개선을 위한 피처 엔지니어링 및 데이터 샘플링 기법 적용 등을 고려할 수 있습니다.

<br>


#### 3) 모델 선택 및 결과 분석
랜덤 포레스트(Random Forest)와 XGBoost는 교차 검증에서는 우수한 성능을 보였으나, 테스트 데이터에서는 다소 낮은 성능을 보였습니다. <br>
이로 인해, 교차 검증에서 더 나은 성능을 보인 머신러닝 모델들이 아닌 테스트 데이터에서 더 우수한 성능을 보인 딥러닝 모델을 최종 모델로 선택하였습니다. <br>
이 선택은 모델의 일반화 성능과 실제 예측 정확도를 고려한 결과입니다.

![image](https://github.com/user-attachments/assets/a7d0cefe-1ad5-4b04-9c2b-b7e59564a15b)

> BCELoss 모델 결과 분석

교차검증 Accuracy: 0.7573      Test Accuracy: 0.7532

BCELoss 기반의 딥러닝 모델은 **교차 검증**과 **테스트 데이터** 모두에서 **상당히 일관된 성능**을 보였습니다. <br>
특히, **테스트 데이터에서의 성능**이 매우 우수하여, 실제 예측 정확도와 **모델의 일반화 능력**을 고려했을 때 **딥러닝 모델**이 더 신뢰할 수 있는 선택이 되었습니다.  <br>


<br>




### 6. 팀원 회고
김성근
>
>
대성원
> 
>
윤정연
> 
> 
유수현
>
>
정승연
>
>
<br>
