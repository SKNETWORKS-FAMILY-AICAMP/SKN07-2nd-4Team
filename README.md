# SKN07-2nd-4Team 

> **íŒ€ì› : ê¹€ì„±ê·¼, ëŒ€ì„±ì›, ìœ ìˆ˜í˜„, ìœ¤ì •ì—°, ì •ìŠ¹ì—°**
</br>

<div align="center">
  <h2><strong> ğŸ“ í†µì‹ ì‚¬ ì´ìš© ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ğŸ“ </h2></strog>
  2024.12.16 ~ 2024.12.17 
</div>
<br><br>
<div align="center">
    <div>
        <img src="https://img.shields.io/badge/Visual%20Studio%20Code-007ACC?style=flat&logo=Visual%20Studio%20Code&logoColor=white"/>
        <img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=Python&logoColor=white"/>
        <img src="https://img.shields.io/badge/Machine%20Learning-FF6F00?style=flat&logo=Artificial%20Intelligence&logoColor=white"/>
        <img src="https://img.shields.io/badge/scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white"/>
        <img src="https://img.shields.io/badge/Deep%20Learning-FCFC00?style=flat&logo=Artificial%20Intelligence&logoColor=white"/>
        <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=PyTorch&logoColor=white">
        <br/>
        <img src="https://img.shields.io/badge/Git-F05032?style=flat&logo=Git&logoColor=white"/>
        <img src="https://img.shields.io/badge/GitHub-181717?style=flat&logo=GitHub&logoColor=white"/>
        <img src="https://img.shields.io/badge/Discord-5865F2?style=flat&logo=Discord&logoColor=white"/>
    </div>
</div>
<br><br>
    
---
<br>

### 1. í”„ë¡œì íŠ¸ ê°œìš” 
ì´ í”„ë¡œì íŠ¸ëŠ” í†µì‹ ì‚¬ì˜ ê³ ê° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ê³ ê°ì˜ ì´íƒˆ(Churn)ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ê³ ê° ì´íƒˆ ì˜ˆì¸¡ì€ ë¹„ì¦ˆë‹ˆìŠ¤ì˜ í•µì‹¬ ë¬¸ì œ ì¤‘ í•˜ë‚˜ë¡œ, ê³ ê°ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ìˆ˜ìµì„±ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
ê³ ê°ì´ ì´íƒˆí•  ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•˜ì—¬, í†µì‹ ì‚¬ëŠ” ì´íƒˆ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê³ ê°ì„ ì‚¬ì „ì— ì‹ë³„í•˜ê³ , ê·¸ì— ë§ëŠ” ë§ˆì¼€íŒ… ì „ëµì„ í†µí•´ ê³ ê°ì„ ìœ ì§€í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

</br>

### 2. í”„ë¡œì íŠ¸ ë°°ê²½ 
- ê³ ê° ì´íƒˆ ë¬¸ì œ
í†µì‹ ì‚¬ì™€ ê°™ì€ ì„œë¹„ìŠ¤ ê¸°ë°˜ ê¸°ì—…ì—ê²Œ ê³ ê° ì´íƒˆì€ ì¤‘ìš”í•œ ê²½ì˜ ë¬¸ì œì…ë‹ˆë‹¤. </br>
ê³ ê°ì´ ì„œë¹„ìŠ¤ë¥¼ ì¤‘ë‹¨í•˜ê±°ë‚˜ ê²½ìŸì‚¬ì˜ ì„œë¹„ìŠ¤ë¡œ ì´ë™í•˜ë©´, ê¸°ì—…ì€ ìˆ˜ìµ ê°ì†ŒëŠ” ë¬¼ë¡ , ìƒˆë¡œìš´ ê³ ê°ì„ ìœ ì¹˜í•˜ê¸° ìœ„í•œ ë§ˆì¼€íŒ… ë¹„ìš©ì´ ê¸‰ì¦í•˜ê²Œ ë©ë‹ˆë‹¤. </br>
ê³ ê° ì´íƒˆì„ ì˜ˆì¸¡í•˜ëŠ” ëŠ¥ë ¥ì„ ê°•í™”í•˜ë©´, ê¸°ì—…ì€ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ ê³ ê°ì„ ìœ ì§€í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ê³ ê° ì¶©ì„±ë„ë¥¼ ë†’ì´ê³  ìˆ˜ìµì„±ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ê³ ê° ì´íƒˆ ë°ì´í„° ë¶„ì„ì˜ í•„ìš”ì„±
ê³¼ê±°ì˜ ê³ ê° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê³ ê°ì˜ ì´íƒˆ íŒ¨í„´ì„ íŒŒì•…í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.</br>
ê³ ê°ì˜ ë‚˜ì´, ì‚¬ìš© ê¸°ê°„, ì„œë¹„ìŠ¤ ì´ìš© íŒ¨í„´, ìš”ê¸ˆì œ ë“± ë‹¤ì–‘í•œ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</br>
ë°ì´í„° ë¶„ì„ì„ í†µí•´ ê³ ê°ì˜ í–‰ë™ì„ ì´í•´í•˜ê³ , ì´íƒˆì„ ë°©ì§€í•  ìˆ˜ ìˆëŠ” ì „ëµì„ ì„¸ìš¸ ìˆ˜ ìˆìœ¼ë©°, ë§ì¶¤í˜• ê³ ê° ê´€ë¦¬ê°€ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.
</br>

### 3. í”„ë¡œì íŠ¸ ëª©í‘œ 

ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ</br>
- ê³ ê°ì˜ ì´íƒˆ ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí•©ë‹ˆë‹¤.

í™œìš© ëª©í‘œ
- ëª¨ë¸ì„ í†µí•´ ì´íƒˆ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê³ ê°ì„ ì‹ë³„í•œ í›„, ê³ ê° ì„¸ë¶„í™”ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ë§ì¶¤í˜• ëŒ€ì‘ ë° ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤.</br>
  ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì—°ë ¹ëŒ€ë‚˜ íŠ¹ì • ìš”ê¸ˆì œì—ì„œ ì´íƒˆì´ ë§ë‹¤ë©´ í•´ë‹¹ ê·¸ë£¹ì— ëŒ€í•œ íŠ¹ë³„í•œ í˜œíƒì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì˜ˆì¸¡ ëª¨ë¸ì„ í†µí•´ ê³ ê° ì´íƒˆì„ ì¤„ì´ê³ , ê³ ê° ìœ ì§€ìœ¨ì„ í–¥ìƒì‹œí‚¤ëŠ” ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤.


</br>

### 4. í”„ë¡œì íŠ¸ ê³¼ì •
 (1) Dataset ì¤€ë¹„
 > Telecom Churn : 13.37MB
 <br>dtypes: float64(26), int64(9), object(23)
 <br>RangeIndex: 51047 entries, 0 to 51046
 <br>Data columns : total 58 columns
 <br>Target : Yes(1) : No(0) = 1 : 4
 <br>ì¶œì²˜ : Kaggle (https://www.kaggle.com/datasets/jpacse/datasets-for-churn-telecom/data?select=cell2celltrain.csv)

<br><br>

 (2) EDA
 >58ê°œì˜ Columnì„ 6ê°œì˜ DataFrameìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ Heatmap ì‹œê°í™”
 <br>
 <img width="400px" src="image/billing_usage_heatmap.png" />
 <img width="400px" src="image/call_stats_heatmap.png" /> 
 <img width="400px" src="image/customer_churn_heatmap.png" /> 
 <img width="400px" src="image/customer_lifestyle_heatmap.png" /> 
 <img width="400px" src="image/customer_profile_heatmap.png" /> 
 <img width="400px" src="image/handset_details_heatmap.png" /> 
 <br>
 
<br><br>

 >Feature ì¤‘ìš”ë„ ìˆœìœ„ì— ë”°ë¼ ìƒìœ„ 40ê°œ í•­ëª©ì„ ì¶”ì¶œí•˜ì—¬ í›ˆë ¨ ë°ì´í„°ë¡œ ì‚¬ìš©
 <img width="900px" height="700" src="image/feature_importance.png" />

<br><br>

 >ìƒìœ„ 40ê°œ í•­ëª© Column ì •ë³´ í™•ì¸
 <img width="500px" height="1000" src="image/columns.png" />

<br><br>
 
 (3) ë°ì´í„° ì „ì²˜ë¦¬ 
 
â–¶ ê²°ì¸¡ì¹˜ ì œê±° 
``` python
df_all = train_file.dropna().copy()
df_all.isnull().sum()
```

<img width="250" alt="image" src="https://github.com/user-attachments/assets/1517f21a-2fb1-407d-92e8-a906499c8d39" /> <img width="250" alt="image" src="https://github.com/user-attachments/assets/487f1ed0-9284-48ba-9739-59bf24bbd03f" />
<br><br>

  â–¶ ë¼ë²¨ê°’(Churn) object --> int ë³€ê²½ 
``` python
churn_label = {'No': 0.0, 'Yes': 1.0} # ìœ ì§€ 0, ì´íƒˆ 1
df_all['Churn'] = df_all['Churn'].map(churn_label)
df_all
```

<br><br>
  â–¶ ë¼ë²¨ê°’(Churn) ë¹„ìœ¨ í™•ì¸
``` python
import numpy as np
np.unique(df_all['Churn'], return_counts=True)
```
<img width="600" alt="image" src="https://github.com/user-attachments/assets/e7e47fef-2fb2-47bc-aefc-48eaae314849" />

<br><br>
  â–¶ ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ x_data,y_data ìƒì„±
``` python
 # ìƒê´€ ê³„ìˆ˜ê°€ ë†’ì€ ì»¬ëŸ¼ì„ ì„ íƒ
 X_data = df_all[['CustomerID','MonthlyRevenue','MonthlyMinutes','TotalRecurringCharge','OverageMinutes','RoamingCalls','PercChangeMinutes','PercChangeRevenues','MonthsInService','RetentionCalls','RetentionOffersAccepted','NewCellphoneUser','NotNewCellphoneUser','ReferralsMadeBySubscriber','AdjustmentsToCreditRating','MadeCallToRetentionTeam','CreditRating','PeakCallsInOut','OffPeakCallsInOut','ReceivedCalls','UnansweredCalls','OutboundCalls','DroppedBlockedCalls','DroppedCalls','InboundCalls','BlockedCalls','DirectorAssistedCalls','CustomerCareCalls','CallWaitingCalls','CurrentEquipmentDays','HandsetRefurbished','IncomeGroup','PrizmCode','Occupation','MaritalStatus','HandsetModels','AgeHH1','ChildrenInHH','HandsetPrice','ThreewayCalls','Handsets']].copy()

# ì´íƒˆìœ¨
y_data = df_all['Churn']
```

<br><br>
 â–¶ One-Hot ì¸ì½”ë”© 
``` python
    # one-hot ì¸ì½”ë”© 
    if 'PrizmCode' in df_file.columns:
        df_file = pd.get_dummies(df_file, columns=['PrizmCode'],drop_first=False)
    if 'Occupation' in df_file.columns:
        df_file = pd.get_dummies(df_file, columns=['Occupation'],drop_first=False)
    if 'MaritalStatus' in df_file.columns:
        df_file = pd.get_dummies(df_file, columns=['MaritalStatus'],drop_first=False)
    
    # Unknown -> -1 , ë‚˜ë¨¸ì§€ëŠ” ìˆ«ìë¡œ í˜• ë³€í™˜
    def label_handset_price(value):
        if value == 'Unknown':
            return -1  # Unknown ê°’ì„ -1ë¡œ ë¼ë²¨ë§
            # return np.nan  # Unknown ê°’ì„ NaNìœ¼ë¡œ ì²˜ë¦¬ (XGBoostì‚¬ìš©)
        else:
            return int(value)  # ë‚˜ë¨¸ì§€ëŠ” ìˆ«ìë¡œ ë³€í™˜
    if df_file['HandsetPrice'].dtype == 'object':
        df_file['HandsetPrice'] = df_file['HandsetPrice'].apply(label_handset_price)

    return df_file
```

<br><br>

 (4) ëª¨ë¸ë§ 
 
 â–¶ ë°ì´í„°ì…‹ ë¶„ë¦¬
``` python
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)
```
<br>

 â–¶ ëª¨ë¸ í›ˆë ¨
 #### âœ” Machine Learning

``` python
# ëª¨ë¸ ì •ì˜
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(class_weight='balanced'),
    "Gradient Boosting": GradientBoostingClassifier(),
    "XGBoost": XGBClassifier(learning_rate=0.1, max_depth=4, n_estimators=100),
    "SGDClassifier": SGDClassifier(loss='hinge'),
    "KNN": KNeighborsClassifier()
}

# Stratified K-Fold ì„¤ì •
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
# NumPy ë°°ì—´ë¡œ ë³€í™˜ 
X_resampled = X_resampled.to_numpy() if isinstance(X_resampled, pd.DataFrame) else X_resampled
y_resampled = y_resampled.to_numpy() if isinstance(y_resampled, pd.Series) else y_resampled

# ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
results = {}
for name, model in models.items():
    print(f"Model: {name}")
    fold_accuracies = []
    fold_roc_aucs = []

    for train_idx, val_idx in skf.split(X_resampled, y_resampled):
        if name in ["Decision Tree", "Random Forest", "Gradient Boosting", "XGBoost"]:
            X_fold_train, X_fold_val = X_resampled[train_idx], X_resampled[val_idx]
        else:
            X_fold_train, X_fold_val = X_train_scaler[train_idx], X_train_scaler[val_idx]

        y_fold_train, y_fold_val = y_resampled[train_idx], y_resampled[val_idx]
        
        model.fit(X_fold_train, y_fold_train)
        y_preds = model.predict(X_fold_val)
        y_probs = model.predict_proba(X_fold_val)[:, 1] if hasattr(model, "predict_proba") else None
        
        acc = accuracy_score(y_fold_val, y_preds)
        roc_auc = roc_auc_score(y_fold_val, y_probs) if y_probs is not None else None
        fold_accuracies.append(acc)
        if roc_auc is not None:
            fold_roc_aucs.append(roc_auc)
```
<br>

â–¶ ëª¨ë¸ ì„±ëŠ¥ ê°œì„ 
``` python
# íŠœë‹ì„ ìœ„í•œ ê³µí†µ ë¶€ë¶„ ì‘ì„± (ìœ„ì™€ ì¤‘ë³µë˜ëŠ” ë¶€ë¶„ ìˆìŒ)
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, roc_auc_score
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)

# ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬
sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X_train, y_train)

# NumPy ë°°ì—´ë¡œ ë³€í™˜

# êµì°¨ê²€ì¦ 
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜
def go_train(select_model,model_name):
    accuracies = []
    roc_aucs = []

    # êµì°¨ê²€ì¦ 
    for train_idx, val_idx in skf.split(X_resampled, y_resampled):
    
        # êµì°¨ê²€ì¦ìš© í›ˆë ¨ ì„¸íŠ¸ì™€ ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬

        # ëª¨ë¸ í•™ìŠµ 
        select_model.fit(X_train, y_train)

        # ê²€ì¦ ì„¸íŠ¸ í‰ê°€
        y_val_pred = select_model.predict(X_val)
        y_val_prob = select_model.predict_proba(X_val)[:, 1]
        accuracies.append(accuracy_score(y_val, y_val_pred))
        roc_aucs.append(roc_auc_score(y_val, y_val_prob))

    # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸
    select_model.fit(X_resampled, y_resampled)  # ì „ì²´ í›ˆë ¨ ë°ì´í„°ë¡œ ì¬í•™ìŠµ
    y_test_pred = select_model.predict(X_test)
    y_test_prob = select_model.predict_proba(X_test)[:, 1]
    test_acc = accuracy_score(y_test, y_test_pred)
    test_roc_auc = roc_auc_score(y_test, y_test_prob)
```
</br>

#### âœ” Deep Learning

``` python
import torch
from torch.utils.data import DataLoader, TensorDataset

train_dataset = torch.utils.data.TensorDataset(torch.tensor( X_train, dtype=torch.float32).to('cuda:0'), 
                                               torch.tensor( y_train.to_numpy(), dtype=torch.float32).to('cuda:0'))
test_dataset  = torch.utils.data.TensorDataset(torch.tensor( X_test,  dtype=torch.float32).to('cuda:0'), 
                                               torch.tensor( y_test.to_numpy(), dtype=torch.float32).to('cuda:0'))

BATCH_SIZE = 32
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)

class ChurnModel(nn.Module):
    def __init__(self, input_size):
        super(ChurnModel,self).__init__()
        self.fc1   = nn.Linear(input_size, 1024)
        self.fc2   = nn.Linear(1024, 1024)
        self.fc3   = nn.Linear(1024, 512)
        self.fc4   = nn.Linear(512, 512)
        self.fc5   = nn.Linear(512, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = F.leaky_relu(x)
        x = self.fc2(x)
        x = F.leaky_relu(x)
        x = self.fc3(x)
        x = F.leaky_relu(x)
        x = self.fc4(x)
        x = F.leaky_relu(x)
        x = self.fc5(x)
        x = torch.sigmoid(x)

        return x

class ChurnModel2(nn.Module):
    def __init__(self, input_size):
        super(ChurnModel2,self).__init__()
        self.input_size = input_size

        self.fc1_1   = nn.Linear(input_size//3, 512)
        self.fc1_2   = nn.Linear(input_size//3, 512)
        self.fc1_3   = nn.Linear(input_size//3 + input_size%3, 512)

        self.fc2_1   = nn.Linear(512, 512)
        self.fc2_2   = nn.Linear(512, 512)
        self.fc2_3   = nn.Linear(512, 512)

        self.fc3   = nn.Linear(512 * 3, 256)
        # self.fc4   = nn.Linear(256, 64)
     
        self.fc5   = nn.Linear(256, 1)

    def forward(self, x):
        d_ = self.input_size//3
        x1 = x[:, :d_]
        x2 = x[:, d_:d_ *2]
        x3 = x[:, d_*2:]

        x1 = self.fc1_1(x1)
        x1 = F.leaky_relu(x1)
        x2 = self.fc1_2(x2)
        x2 = F.leaky_relu(x2)
        x3 = self.fc1_3(x3)
        x3 = F.leaky_relu(x3)

        x1 = self.fc2_1(x1)
        x1 = F.leaky_relu(x1)
        x2 = self.fc2_2(x2)
        x2 = F.leaky_relu(x2)
        x3 = self.fc2_3(x3)
        x3 = F.leaky_relu(x3)

        x4 = torch.cat((x1, x2, x3), dim=1)
        # print(x1.shape, x2.shape, x3.shape, x4.shape)
        
        x4 = self.fc3(x4)
        x4 = F.leaky_relu(x4)

        # x4 = self.fc4(x4)
        # x4 = F.leaky_relu(x4)
  
        x4 = self.fc5(x4)
        x4 = torch.sigmoid(x4)

        return x4

def train(model, train_loader, optimizer, loss_fn):
    model.train()
    total_acc, total_loss = 0, 0
    for X, y in train_loader:
        optimizer.zero_grad()
        preds = model(X)
        # display(preds, y)
        loss = loss_fn(preds, y.reshape(-1,1))
        loss.backward()
        optimizer.step()

        total_acc += ((preds>=0.5).float() ==  y.reshape(-1,1)).float().sum().item()
        total_loss += loss.item()*y.size(0)
        # print(f'total_loss = {total_loss}, total_acc={total_acc}')
    return total_acc/len(train_loader.dataset), total_loss/len(train_loader.dataset)

def evaluate(model, test_loader, loss_fn):
    model.eval()
    total_acc, total_loss = 0, 0

    with torch.no_grad():  
        for X, y in test_loader:
            preds = model(X)
            loss = loss_fn(preds, y.reshape(-1,1))

            total_acc += ((preds>=0.5).float() ==  y.reshape(-1,1)).float().sum().item()
            total_loss += loss.item()*y.size(0)

    return total_acc/len(test_loader.dataset), total_loss/len(test_loader.dataset)

num_epochs = 10

torch.manual_seed(1)

def learning(num_epochs,model, train_loader, test_loader, optimizer, loss_fn):
    for epoch in range(num_epochs):
        acc_train, loss_train = train(model, train_loader, optimizer, loss_fn)
        acc_valid, loss_valid = evaluate(model, test_loader, loss_fn)
        print(f'ì—í¬í¬ {epoch} ì •í™•ë„: {acc_train:.4f} ê²€ì¦ ì •í™•ë„: {acc_valid:.4f} \
            í›ˆë ¨ Loss: {loss_train:.4f} ê²€ì¦ Loss: {loss_valid:.4f}')
    #     break

loss_fns = {'BCELoss': nn.BCELoss(), 
            'HingeEmbeddingLoss': nn.HingeEmbeddingLoss(), 
            'BCEWithLogitsLoss': nn.BCEWithLogitsLoss() }

models = {'ChurnModel' : ChurnModel(train_dataset[0][0].__len__()), 
          'ChurnModel2': ChurnModel2(train_dataset[0][0].__len__())}
for model_name, model in models.items():
    model.to('cuda:0')
    print(f'{"*"*20} {model_name} {"*"*20}')
    for fn_name, loss_fn in loss_fns.items():
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        print(f'{"-"*15} {fn_name} {"-"*15}')
        learning(num_epochs, model, train_loader, test_loader, optimizer, loss_fn)
```
<br><br>

### 5. í”„ë¡œì íŠ¸ ê²°ê³¼

<br>

**1) ëª¨ë¸ ì„±ëŠ¥ í‰ê°€**

<br>

ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì€ êµì°¨ ê²€ì¦ì„ í†µí•´ ê²€í† ë˜ì—ˆìœ¼ë©°, ì£¼ìš” í‰ê°€ì§€í‘œì¸ **ì •í™•ë„(Accuracy)** ì™€ **ROC-AUC** ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.

<br>

**2) ëª¨ë¸ë§**

<br>

ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression), ê²°ì • íŠ¸ë¦¬(Decision Tree), ëœë¤ í¬ë ˆìŠ¤íŠ¸(Random Forest), ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…(Gradient Boosting), XGBoost ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì´ ì‹¤í—˜ë˜ì—ˆìŠµë‹ˆë‹¤.
* __ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)__
  - Mean Accuracy: 0.7747339742435884
  - Mean ROC-AUC: 0.827727390454782
  
* **ê²°ì • íŠ¸ë¦¬(Decision Tree)**
  - Mean Accuracy: 0.7073191489624133
  - Mean ROC-AUC: 0.7073190731398483
  
* **ëœë¤ í¬ë ˆìŠ¤íŠ¸(Random Forest)**
  - Mean Accuracy: 0.8036210039245082
  - Mean ROC-AUC: 0.8715462593154809
  
* **ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…(Gradient Boosting)**
  - Mean Accuracy: 0.7963334335743306
  - Mean ROC-AUC: 0.8556458031733211
  
* **XGBoost**
  - Mean Accuracy: 0.8003021013375582
  - Mean ROC-AUC: 0.8620662223104063

* **SGDClassifier**
  - Mean Accuracy: 0.7741193830961918
  - Mean ROC-AUC: N/A

* **KNN(K-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜)**
  - Mean Accuracy: 0.7421592897541187
  - Mean ROC-AUC: 0.8078817540896164
    

ê° ëª¨ë¸ì˜ ê²°ê³¼ëŠ” ê³ ê° ì´íƒˆì„ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆì–´ **ìƒë‹¹íˆ ë†’ì€ ì •í™•ë„**ë¥¼ ê¸°ë¡í–ˆìœ¼ë©°, íŠ¹íˆ **ëœë¤ í¬ë ˆìŠ¤íŠ¸**ì™€ **XGBoost** ëª¨ë¸ì€ **ROC-AUC** ì ìˆ˜ê°€ ë†’ê²Œ ë‚˜ì™€, ëª¨ë¸ì˜ **ë¶„ë¥˜ ì„±ëŠ¥**ì´ ìš°ìˆ˜í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

<br>

**3) ëª¨ë¸ ì„ íƒ ë° ê²°ê³¼ ë¶„ì„**

<br>

ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì€ êµì°¨ ê²€ì¦ì„ í†µí•´ ê²€í† ë˜ì—ˆìœ¼ë©°, ì£¼ìš” í‰ê°€ì§€í‘œì¸ **ì •í™•ë„(Accuracy)**, **ROC-AUC**ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì˜€ì„ë•Œ ê°€ì¥ ë†’ì€ ì ìˆ˜ê°€ ë‚˜ì™”ë˜ XGBoost ëª¨ë¸ì„ ì„ íƒí•˜ì—¬ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.

<img width="400" alt="image" src="https://github.com/user-attachments/assets/5e5c5dfa-0b81-4481-a154-d350d9cc1d76" /> 

<br> êµì°¨ê²€ì¦ Mean Accuracy: 0.8048
- í‰ê·  **80.48**%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ë©°, ì „ì²´ ëª¨ë¸ ì¤‘ì—ì„œ ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ë¬¸ì œì—ì„œ ìƒë‹¹íˆ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
  
êµì°¨ê²€ì¦ Mean ROC-AUC: 0.8657
- í‰ê·  **0.8657**ì˜ ROC-AUCë¥¼ ê¸°ë¡í•˜ì˜€ìœ¼ë©°, ì´ëŠ” ì´ ëª¨ë¸ì´ ì´íƒˆ ì˜ˆì¸¡ì—ì„œ ê¸ì •ì ì¸ í´ë˜ìŠ¤(ì´íƒˆ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê³ ê°)ì™€ ë¶€ì •ì ì¸ í´ë˜ìŠ¤(ì´íƒˆí•˜ì§€ ì•Šì€ ê³ ê°)ë¥¼ ì˜ êµ¬ë³„í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë†’ì€ ROC-AUC ê°’ì€ ëª¨ë¸ì´ ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ì˜ ì‘ë™í•˜ê³  ìˆë‹¤ëŠ” ì¦ê±°ì…ë‹ˆë‹¤.

Test Accuracy: 0.7201
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œëŠ” **72.01**%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ì˜€ìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì´ ì‹¤ì œ ë°ì´í„°ì— ëŒ€í•´ì„œë„ ê½¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ êµì°¨ ê²€ì¦ì—ì„œ ë³´ì˜€ë˜ ì„±ëŠ¥ë³´ë‹¤ëŠ” ë‹¤ì†Œ ë‚®ì€ ê²°ê³¼ë¡œ, ì´ëŠ” ê³¼ì í•©(overfitting) ë¬¸ì œë‚˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ íŠ¹ì„± ì°¨ì´ ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Test ROC-AUC: 0.6813
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ROC-AUCëŠ” **0.6813**ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œë„ ì–´ëŠ ì •ë„ êµ¬ë³„ ì„±ëŠ¥ì„ ë³´ì˜€ì§€ë§Œ, êµì°¨ ê²€ì¦ì—ì„œì˜ ì„±ëŠ¥ë³´ë‹¤ëŠ” ë‚®ì€ ê²°ê³¼ì…ë‹ˆë‹¤. ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì´ ì•½ê°„ ë¶€ì¡±í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

<br>


**4) ì„±ëŠ¥ ë¶„ì„ ë° ì‹œì‚¬ì **
- **XGBoost ëª¨ë¸**ì€ êµì°¨ ê²€ì¦ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë‚˜, ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œëŠ” ë‹¤ì†Œ ì„±ëŠ¥ì´ ë–¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ëŠ” í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°„ì˜ ì°¨ì´, ë˜ëŠ” ëª¨ë¸ì´ ì¼ë¶€ ê³¼ì í•©ëœ ê²°ê³¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ì •í™•ë„**ì™€ **ROC-AUC** ëª¨ë‘ ê½¤ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ì—ˆê³ , íŠ¹íˆ ROC-AUC ì§€í‘œëŠ” ì´íƒˆ ì˜ˆì¸¡ ë¬¸ì œì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë”ìš± ì˜ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì§€í‘œë¡œ, XGBoostê°€ ê¸ì •ì  í´ë˜ìŠ¤ë¥¼ ì˜ êµ¬ë¶„í•˜ëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.
- **ëª¨ë¸ì˜ í–¥í›„ ê°œì„  ë°©í–¥**ìœ¼ë¡œëŠ”, ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì¶”ê°€ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë° ë°ì´í„° ìƒ˜í”Œë§ ê¸°ë²• ì ìš© ë“±ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<br>

<img width="469" alt="image" src="https://github.com/user-attachments/assets/e1690d1f-76e2-421e-861d-d62c43052298" />
<img width="478" alt="image" src="https://github.com/user-attachments/assets/e956f1d3-0b2e-4e52-9726-600371a77052" />


### 6. íŒ€ì› íšŒê³ 
ê¹€ì„±ê·¼
>
>
ëŒ€ì„±ì›
> 
>
ìœ¤ì •ì—°
> 
> 
ìœ ìˆ˜í˜„
>
>
ì •ìŠ¹ì—°
>
>
<br>
